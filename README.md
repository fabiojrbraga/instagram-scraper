# BRCOM Scraper API

Sistema de raspagem de dados de sites usando IA Generativa, Browser Automation e Browserless.

## üìã Caracter√≠sticas

- **Browser Automation**: Usa Browserless para automa√ß√£o de navegador headless
- **IA Generativa**: Integra√ß√£o com OpenAI para extra√ß√£o inteligente de dados
- **An√°lise H√≠brida**: Combina vis√£o computacional com processamento de texto
- **API REST**: FastAPI com endpoints bem documentados
- **PostgreSQL**: Persist√™ncia de dados estruturados
- **Docker**: Pronto para deploy em EasyPanel e outros ambientes containerizados

## Arquitetura

- **Camada API (FastAPI)**:
  - endpoints de scraping: `/api/scrape`, `/api/profiles/scrape`, `/api/generic_scrape`, `/api/investing_scrape`
  - endpoints de consulta: `/api/scrape/{job_id}`, `/api/scrape/{job_id}/results`, `/api/profiles/{username}/*`
  - endpoints administrativos de sessao: `/api/instagram_sessions`, `/api/instagram_sessions/{session_id}/deactivate`
- **Autenticacao da API**:
  - API privada por header (`X-API-Key` por padrao)
  - excecao padrao: `/api/health`
- **Orquestracao de scraping**:
  - `browser-use` para navegacao guiada por LLM
  - `BrowserlessClient` para screenshot/HTML/execucao JS (com fallback de compatibilidade)
- **Sessoes Instagram**:
  - login humano via `scripts/capture_instagram_session.py`
  - import e persistencia por conta via `scripts/import_instagram_session.py`
  - selecao de sessao por request usando `session_username`
- **Persistencia (PostgreSQL)**:
  - tabelas de dominio: `profiles`, `posts`, `interactions`, `scraping_jobs`
  - tabelas de sessao: `instagram_sessions`, `investing_sessions`

## üöÄ Instala√ß√£o

### Pr√©-requisitos

- Docker e Docker Compose
- Python 3.11+ (para desenvolvimento local)
- Conta Browserless com token
- API Key OpenAI

### Vari√°veis de Ambiente

Copie `.env.example` para `.env` e configure:

```bash
cp .env.example .env
```

Edite `.env` com suas credenciais:

```env
# FastAPI
FASTAPI_ENV=production
FASTAPI_HOST=0.0.0.0
FASTAPI_PORT=8000

# PostgreSQL
DATABASE_URL=postgresql://user:password@host:5432/instagram_scraper

# Browserless
BROWSERLESS_HOST=https://your-browserless-instance.com
BROWSERLESS_TOKEN=your-browserless-token

# OpenAI
OPENAI_API_KEY=sk-your-api-key-here
```

### Login humano + import de sessao (sem senha no Browser Use)

Se voce nao quiser expor usuario/senha do Instagram para a IA, use o fluxo manual:

```bash
# 1) Capturar storage_state apos login humano (abre navegador)
python scripts/capture_instagram_session.py --mode local

# 2) Importar sessao no banco
python scripts/import_instagram_session.py --username seu_usuario
```

Arquivo gerado: `.secrets/instagram_storage_state.json` (ignorado no git).

Para escolher uma sessao especifica na API, envie `session_username` no body:

```json
{
  "profile_url": "https://www.instagram.com/username/",
  "session_username": "conta_logada"
}
```

Endpoints administrativos de sessao:

```bash
# listar sessoes (ativas por padrao)
GET /api/instagram_sessions?active_only=true&username=conta_logada

# desativar sessao especifica
POST /api/instagram_sessions/{session_id}/deactivate
```

Observacao: o script de captura salva tambem o `user_agent` da sessao e o scraper tenta reutilizar esse valor nos requests Browserless (`userAgent` no payload, com fallback automatico quando nao suportado).

### Desenvolvimento Local

```bash
# Instalar depend√™ncias
pip install -r requirements.txt

# Instalar Chromium para captura manual de sess√£o local
python -m playwright install chromium

# Iniciar com Docker Compose
docker-compose up -d

# Acessar API
# http://localhost:8000
# Documenta√ß√£o: http://localhost:8000/docs
```

### Deploy em EasyPanel

1. **Criar novo aplicativo**:
   - Tipo: Docker
   - Dockerfile: Use o fornecido
   - Porta: 8000

2. **Configurar vari√°veis de ambiente** no EasyPanel:
   ```
   DATABASE_URL=postgresql://...
   BROWSERLESS_HOST=...
   BROWSERLESS_TOKEN=...
   OPENAI_API_KEY=sk-...
   ```

3. **Deploy**:
   - Push para reposit√≥rio Git
   - EasyPanel far√° build e deploy automaticamente

## üìö Uso da API

### Autentica√ß√£o (API privada)

Quase todos os endpoints exigem chave no header `X-API-Key` (ou o nome configurado em `API_AUTH_HEADER_NAME`).
Somente `/api/health` √© p√∫blico por padr√£o.

### 1. Iniciar Scraping

```bash
curl -X POST http://localhost:8000/api/scrape \
  -H "X-API-Key: change-me" \
  -H "Content-Type: application/json" \
  -d '{"profile_url": "https://instagram.com/username", "session_username": "conta_logada"}'
```

Resposta:
```json
{
  "id": "job-uuid",
  "profile_url": "https://instagram.com/username",
  "status": "pending",
  "created_at": "2024-01-28T10:30:00Z"
}
```

### 2. Verificar Status

```bash
curl http://localhost:8000/api/scrape/{job_id} \
  -H "X-API-Key: change-me"
```

### 3. Obter Resultados

```bash
curl http://localhost:8000/api/scrape/{job_id}/results \
  -H "X-API-Key: change-me"
```

Resposta:
```json
{
  "job_id": "job-uuid",
  "status": "completed",
  "profile": {
    "username": "example_user",
    "profile_url": "https://instagram.com/example_user",
    "bio": "Bio do perfil",
    "is_private": false,
    "follower_count": 1500,
    "posts": [
      {
        "post_url": "https://instagram.com/p/ABC123",
        "caption": "Caption do post",
        "like_count": 250,
        "comment_count": 15,
        "interactions": [
          {
            "type": "comment",
            "user_url": "https://instagram.com/user1",
            "user_username": "user1",
            "user_bio": "Bio do user1",
            "is_private": false,
            "comment_text": "Que legal! üòç"
          }
        ]
      }
    ]
  },
  "total_posts": 5,
  "total_interactions": 42,
  "completed_at": "2024-01-28T10:35:00Z"
}
```

### 4. Obter Perfil

```bash
curl http://localhost:8000/api/profiles/username \
  -H "X-API-Key: change-me"
```

### 5. Obter Posts do Perfil

```bash
curl http://localhost:8000/api/profiles/username/posts?skip=0&limit=10 \
  -H "X-API-Key: change-me"
```

### 6. Obter Intera√ß√µes do Perfil

```bash
curl http://localhost:8000/api/profiles/username/interactions?skip=0&limit=50 \
  -H "X-API-Key: change-me"
```

### 7. Listar sess√µes Instagram

```bash
curl "http://localhost:8000/api/instagram_sessions?active_only=true" \
  -H "X-API-Key: change-me"
```

### 8. Desativar sess√£o Instagram

```bash
curl -X POST http://localhost:8000/api/instagram_sessions/{session_id}/deactivate \
  -H "X-API-Key: change-me"
```

## üóÑÔ∏è Estrutura do Banco de Dados

### Profiles
```sql
- id (UUID)
- instagram_username (String, Unique)
- instagram_url (String)
- bio (Text)
- is_private (Boolean)
- follower_count (Integer)
- verified (Boolean)
- created_at (DateTime)
- updated_at (DateTime)
- last_scraped_at (DateTime)
```

### Posts
```sql
- id (UUID)
- profile_id (FK)
- post_url (String, Unique)
- caption (Text)
- like_count (Integer)
- comment_count (Integer)
- posted_at (DateTime)
- created_at (DateTime)
- updated_at (DateTime)
```

### Interactions
```sql
- id (UUID)
- post_id (FK)
- profile_id (FK)
- user_username (String)
- user_url (String)
- user_bio (Text)
- user_is_private (Boolean)
- interaction_type (Enum: like, comment, share, save)
- comment_text (Text)
- comment_likes (Integer)
- comment_replies (Integer)
- created_at (DateTime)
- updated_at (DateTime)
```

### Scraping Jobs
```sql
- id (UUID)
- profile_url (String)
- status (String: pending, running, completed, failed)
- started_at (DateTime)
- completed_at (DateTime)
- error_message (Text)
- posts_scraped (Integer)
- interactions_scraped (Integer)
- created_at (DateTime)
```

## üîÑ Fluxo de Scraping

1. **Requisi√ß√£o**: Cliente envia URL do perfil
2. **Job Creation**: Sistema cria job com status "pending"
3. **Background Task**: Scraping inicia em background
4. **Navigation**: Browserless acessa o perfil
5. **Capture**: Screenshots e HTML s√£o capturados
6. **Extraction**: IA extrai dados estruturados
7. **Persistence**: Dados s√£o salvos no PostgreSQL
8. **Completion**: Job atualizado com status "completed"
9. **Retrieval**: Cliente consulta resultados via API

## üìä Dados Extra√≠dos

### Por Perfil
- Username
- Bio
- Status privado/p√∫blico
- N√∫mero de seguidores
- Verifica√ß√£o azul
- Data da √∫ltima raspagem

### Por Post
- URL do post
- Caption/Descri√ß√£o
- N√∫mero de likes
- N√∫mero de coment√°rios
- Data do post

### Por Intera√ß√£o
- Tipo (like, coment√°rio, etc)
- Username de quem interagiu
- URL do perfil do usu√°rio
- Bio do usu√°rio
- Status privado/p√∫blico do usu√°rio
- Texto do coment√°rio (se aplic√°vel)
- Likes no coment√°rio
- Respostas ao coment√°rio

## ‚öôÔ∏è Configura√ß√£o Avan√ßada

### Limites de Taxa

Adicione delays aleat√≥rios para simular comportamento humano:

```python
# Em instagram_scraper.py
delay = random.uniform(1, 5)  # 1-5 segundos entre a√ß√µes
await asyncio.sleep(delay)
```

### Cache de Resultados

Implemente cache para reduzir custos de IA:

```python
from functools import lru_cache

@lru_cache(maxsize=100)
async def extract_profile_info(url: str):
    # Cached extraction
    pass
```

### Retry Logic

Configure retries autom√°ticos:

```python
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10)
)
async def scrape_profile(url: str):
    # Will retry up to 3 times
    pass
```

## üêõ Troubleshooting

### Erro: "Browserless n√£o acess√≠vel"
- Verifique `BROWSERLESS_HOST` e `BROWSERLESS_TOKEN`
- Teste conex√£o: `curl -H "Authorization: Bearer TOKEN" https://host/health`

### Erro: "OpenAI API error"
- Verifique `OPENAI_API_KEY`
- Confirme quota e saldo da conta

### Erro: "PostgreSQL connection failed"
- Verifique `DATABASE_URL`
- Confirme que PostgreSQL est√° rodando

### Erro: "Instagram bloqueou requisi√ß√£o"
- Aumente delays entre requisi√ß√µes
- Considere usar proxy
- Implemente retry com backoff exponencial

## üìà Performance

### Otimiza√ß√µes Implementadas

1. **Multi-stage Docker Build**: Reduz tamanho da imagem
2. **Connection Pooling**: Reutiliza conex√µes PostgreSQL
3. **Async/Await**: Processamento n√£o-bloqueante
4. **Background Tasks**: Scraping n√£o bloqueia API
5. **Batch Processing**: Processa m√∫ltiplos itens por chamada IA

### Benchmarks Esperados

- Scraping de 1 perfil: 30-60 segundos
- Extra√ß√£o de 5 posts: 15-30 segundos
- Custo por perfil: $0.50 - $1.50 (com gpt-4-mini)

## üîê Seguran√ßa

- Vari√°veis sens√≠veis via `.env` (n√£o commitadas)
- CORS configurado para produ√ß√£o
- Rate limiting (implementar conforme necess√°rio)
- Valida√ß√£o de entrada com Pydantic
- SQL Injection protection via SQLAlchemy ORM

## üìù Logging

Logs s√£o configurados por n√≠vel:

```
INFO: Opera√ß√µes normais
WARNING: Situa√ß√µes anormais
ERROR: Erros que precisam aten√ß√£o
DEBUG: Informa√ß√µes detalhadas (desenvolvimento)
```

Visualize logs:
```bash
docker logs instagram-scraper-app -f
```

## ü§ù Contribuindo

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudan√ßas (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja `LICENSE` para mais detalhes.

## üìû Suporte

Para suporte, abra uma issue no reposit√≥rio ou entre em contato.

## üôè Agradecimentos

- OpenAI pela API GPT
- Browserless pela infraestrutura de navegador
- FastAPI pela framework web
- SQLAlchemy pelo ORM

---

**√öltima atualiza√ß√£o**: 04 de Fevereiro de 2026
**Vers√£o**: 1.0.0
